{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blog Post: Women in Data Science\n",
    "\n",
    "In this blog post, I will first seek to better understand the under-representation of women in engineering and the computing sciences, the harms that this causes for everyone, why this happens, and some steps towards improving it. Then, I will discuss the Women in Data Science Conference at Middlebury, one such step taken to help give women a sense of belonging in fields that are more stereotypically dominated by men. Each speaker shared important lessons about their time in data science, and how data science is used in the real world. Then I will summarize my learnings from the readings regarding women in data science, attending the conference, and writing this blog post!\n",
    "\n",
    "There are a few reasons why it is problematic that women are underrepresented in engineering and computing sciences. First off, and potentially most obviously, this is a problem for women. When women cannot work in fields, their needs may be overlooked by their male counterparts. However, this under-representation is not just a problem for women - its a problem for everyone. Research has found that innovation soars with greater diversity in the work force. Further research has shown that low-performing men are frequently hired over high-performing women. This combination of factors leaves a large talent pool untapped, and many breakthroughs on the bench. Increased diversity has also been found to increase productivity.\n",
    "\n",
    "Many fields that have found themselves under-representing women historically have made huge gains with respect to representation since the 2000s. Computing represents the unique exception to the rule - while almost 40% of the field was women in 1985, that percent has declined continuously and in 2013, women only made up 18% of the workforce. This percent is reminiscent of the 1970s. One reason that could be behind this is the narrow focus of many engineering jobs; there is rarely a drive to discuss and consider social and ethical responsibilities of ones' job. As women have a higher preference for attaining a clear social purpose, this leads to imbalance. Other issues include isolation, stereotyping, and challenges with work life balance that are culturally expected of many women like marriage and children. Additionally, women are statistically more likely to be the victim of sexual assault.\n",
    "\n",
    "Despite these challenges, progress is being made towards change. One idea is to include components of ethical and community values in both college courses and the work place. This can help women feel as if they are making a contribution to society. Feeling welcome and wanted can improve motivation, perseverance, and commitment to computing, boosting interest, and retention of women in the field. Anti-harassment and anti-assault policies and trainings can feel safe in the workplace. Introducing women to computing and engineering from a young age and exposing students to female and non-binary role models who have successful careers can provide a sense of belonging. One example of that is the Women in Data Science conference hosted annually at Middlebury College.\n",
    "\n",
    "The conference opened with Professor Amy Yuen's lightning talk. As a political science professor, one of her recent areas of study has been representation in the UN Security council - more specifically whether the representation was equal. She explained how it seemed unlikely; the council consists of only 15 member countries at a time. Moreover, 1/3 of these countries always remain on the council with veto privileges while the other 10 seats are campaigned for by countries based on region. Professor Yuen determined that a successful member would have a high output discovered that wealthy countries were not necessarily more productive when on the council. Rather, sponsorship was a significant influencing factor. Somewhat surprisingly, she also determined that the council has somewhat equal representation among the seats that are campaigned for.\n",
    "\n",
    "The keynote presenter, Professor Sarah Brown, spoke about the ethical implications of involving machine learning in our daily life. As usage of such algorithms increases, so does the need to ensure that they are capable of fairly analyzing data. To frame her talk, she shared three keys, or epiphanies that she has had, and how they apply to data science. Each key related understanding the context of data to its proper usage. \n",
    "\n",
    "The first key was that Professor Brown discovered was that context is necessary to understand primary sources. The following example in particular resonated with me. Her project involved involved diagnosing patients with PTSD. The formerly used method applied a threshold, below which patients were no longer assessed. Professor Brown, after gaining a better understanding of how the data was interpreted, was able to make a minor adjustment which drastically decreased misclassification of patients who had PTSD as not having PTSD. As someone who is deeply interested in the healthcare system, how access can be increased, and the role data science is and will play in it, I found this insightful.\n",
    "\n",
    "Continuing on, she shared her discovery that disciplines are communities. This was an essential learning; most people who work with data science are, well, computer scientists, and don't have the expertise to interpret the data in context. Involving others from the community, and even other communities from relevant fields can lessen bias and bolster information gained from the results.\n",
    "\n",
    "The final key was to meet people where they are. While she was on the board of the National Society for Black Engineers, she discovered a startling breakdown of how information was passed on. The national board received positive feedback from individual chapter heads, the policies still weren't being implemented. Eventually, they realized that student organizations didn't have the resources or motivation to make these policies happen. This translated to machine learning when Professor Brown noticed that once an algorithm is accurate, producers will hesitate to make it fair, not sure if it is worth the trade-off in accuracy. Her proposed solution was to indicate whether a model was fair before fitting it, to reduce hesitance to make a model fair.\n",
    "\n",
    "The second lightning talk was shared by Professor Jessica L'Roe highlighted the importance of context in research. She went into detail about how she collected quantitative and qualitative data during her work with deforestation directly from local communities that were impacted. By doing so, she discovered that the tree planting was carried out primarily by foreigners, and they were not planting local species of trees. As a result of the increased interest in tree planting by foreigners, much of the farming land was being purchased, and mothers local to the area had begun prioritizing education over agriculture as a future for their children due to concerns of insufficient land to be farmed. Without gathering data from locals directly impacted, Professor L'Roe never would have discovered the subtle intricacies of her data, and how it was changing life for future generations of locals.\n",
    "\n",
    "Professor Biester (one of our own Middlebury Computer Science Professors!) shared a talk about her research on mental health and social media presence. To collect data, she took on the impressive feat of scraping a massive amount of data from reddit. Then, she searched the data for instances of specific first person declarations of having been diagnosed with depression. The assumption that makes this work is that although a few users may lie, the percentage of users who claim to have been diagnosed and but have not been is negligible compared to those who claim to have been diagnosed and actually have been diagnosed, and vice versa for those who did not claim to be diagnosed. I learned that looking at the data and thinking about what must be accounted for, and what factors are negligible is an important step in cleaning and preparing the data.\n",
    "\n",
    "First and foremost, writing this blog post forced me to sit with how tall of a mountain we will have to climb to have equal representation, opportunity, and treatment of women working in STEM. I was previously aware of the under-representation of women in these fields, I didn't quite realize how deep the roots were of this issue, or how difficult it would be to unravel them. From stereotype threat to a sense of belonging, it is challenging to be a successful woman in STEM. However, I was pleased to see the deep thought that went into some steps that have been taken (by, for example, Harvey Mudd College), and even just an increased awareness that this is, indeed an issue (thanks to big tech companies for publishing percentages of women in the workforce). While this mountain might be a tall one, it's definitely worth climbing. I hope to learn more about steps I can take to reduce all kinds of bias in algorithms that I implement by considering what biases I have beforehand and asking experts for help to reduce them."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
