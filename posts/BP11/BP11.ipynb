{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blog Post 11: Deep Music Genre Classification\n",
    "Well, I've been hoping to do a deep learning blog post all semester, so I'm really excited to give this one a shot! The first step will be to properly format the data, and then perform text vectorization, since lyrics are words, which cannot function as features. Then, I will collate batches. Finally, I will be prepared to create a model and evaluate its accuracy. I will create 3 models, one learning from just the lyrics, one learning from just the features, and one learning from both. Once the models have successfully performed better than the base rate, I will compare the accuracy across the three models to see which one would be the most promising to continue to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/PhilChodrow/PIC16B/master/datasets/tcc_ceds_music.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>release_date</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>len</th>\n",
       "      <th>dating</th>\n",
       "      <th>violence</th>\n",
       "      <th>world/life</th>\n",
       "      <th>...</th>\n",
       "      <th>sadness</th>\n",
       "      <th>feelings</th>\n",
       "      <th>danceability</th>\n",
       "      <th>loudness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>energy</th>\n",
       "      <th>topic</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mukesh</td>\n",
       "      <td>mohabbat bhi jhoothi</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>hold time feel break feel untrue convince spea...</td>\n",
       "      <td>95</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.063746</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380299</td>\n",
       "      <td>0.117175</td>\n",
       "      <td>0.357739</td>\n",
       "      <td>0.454119</td>\n",
       "      <td>0.997992</td>\n",
       "      <td>0.901822</td>\n",
       "      <td>0.339448</td>\n",
       "      <td>0.137110</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>frankie laine</td>\n",
       "      <td>i believe</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>believe drop rain fall grow believe darkest ni...</td>\n",
       "      <td>51</td>\n",
       "      <td>0.035537</td>\n",
       "      <td>0.096777</td>\n",
       "      <td>0.443435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.331745</td>\n",
       "      <td>0.647540</td>\n",
       "      <td>0.954819</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.325021</td>\n",
       "      <td>0.263240</td>\n",
       "      <td>world/life</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>johnnie ray</td>\n",
       "      <td>cry</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>sweetheart send letter goodbye secret feel bet...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.225422</td>\n",
       "      <td>0.456298</td>\n",
       "      <td>0.585288</td>\n",
       "      <td>0.840361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351814</td>\n",
       "      <td>0.139112</td>\n",
       "      <td>music</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>pérez prado</td>\n",
       "      <td>patricia</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>kiss lips want stroll charm mambo chacha merin...</td>\n",
       "      <td>54</td>\n",
       "      <td>0.048249</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225889</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.686992</td>\n",
       "      <td>0.744404</td>\n",
       "      <td>0.083935</td>\n",
       "      <td>0.199393</td>\n",
       "      <td>0.775350</td>\n",
       "      <td>0.743736</td>\n",
       "      <td>romantic</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>giorgos papadopoulos</td>\n",
       "      <td>apopse eida oneiro</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>till darling till matter know till dream live ...</td>\n",
       "      <td>48</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.417772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.291671</td>\n",
       "      <td>0.646489</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.597073</td>\n",
       "      <td>0.394375</td>\n",
       "      <td>romantic</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           artist_name            track_name  release_date genre  \\\n",
       "0           0                mukesh  mohabbat bhi jhoothi          1950   pop   \n",
       "1           4         frankie laine             i believe          1950   pop   \n",
       "2           6           johnnie ray                   cry          1950   pop   \n",
       "3          10           pérez prado              patricia          1950   pop   \n",
       "4          12  giorgos papadopoulos    apopse eida oneiro          1950   pop   \n",
       "\n",
       "                                              lyrics  len    dating  violence  \\\n",
       "0  hold time feel break feel untrue convince spea...   95  0.000598  0.063746   \n",
       "1  believe drop rain fall grow believe darkest ni...   51  0.035537  0.096777   \n",
       "2  sweetheart send letter goodbye secret feel bet...   24  0.002770  0.002770   \n",
       "3  kiss lips want stroll charm mambo chacha merin...   54  0.048249  0.001548   \n",
       "4  till darling till matter know till dream live ...   48  0.001350  0.001350   \n",
       "\n",
       "   world/life  ...   sadness  feelings  danceability  loudness  acousticness  \\\n",
       "0    0.000598  ...  0.380299  0.117175      0.357739  0.454119      0.997992   \n",
       "1    0.443435  ...  0.001284  0.001284      0.331745  0.647540      0.954819   \n",
       "2    0.002770  ...  0.002770  0.225422      0.456298  0.585288      0.840361   \n",
       "3    0.001548  ...  0.225889  0.001548      0.686992  0.744404      0.083935   \n",
       "4    0.417772  ...  0.068800  0.001350      0.291671  0.646489      0.975904   \n",
       "\n",
       "   instrumentalness   valence    energy       topic  age  \n",
       "0          0.901822  0.339448  0.137110     sadness  1.0  \n",
       "1          0.000002  0.325021  0.263240  world/life  1.0  \n",
       "2          0.000000  0.351814  0.139112       music  1.0  \n",
       "3          0.199393  0.775350  0.743736    romantic  1.0  \n",
       "4          0.000246  0.597073  0.394375    romantic  1.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_features = ['dating', 'violence', 'world/life', 'night/time','shake the audience','family/gospel', 'romantic', 'communication','obscene', 'music', 'movement/places', 'light/visual perceptions','family/spiritual', 'like/girls', 'sadness', 'feelings', 'danceability','loudness', 'acousticness', 'instrumentalness', 'valence', 'energy'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pop' 'country' 'blues' 'jazz' 'reggae' 'rock' 'hip hop']\n",
      "[0 1 2 3 4 5 6]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>release_date</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>len</th>\n",
       "      <th>dating</th>\n",
       "      <th>violence</th>\n",
       "      <th>world/life</th>\n",
       "      <th>...</th>\n",
       "      <th>sadness</th>\n",
       "      <th>feelings</th>\n",
       "      <th>danceability</th>\n",
       "      <th>loudness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>energy</th>\n",
       "      <th>topic</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mukesh</td>\n",
       "      <td>mohabbat bhi jhoothi</td>\n",
       "      <td>1950</td>\n",
       "      <td>0</td>\n",
       "      <td>hold time feel break feel untrue convince spea...</td>\n",
       "      <td>95</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.063746</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380299</td>\n",
       "      <td>0.117175</td>\n",
       "      <td>0.357739</td>\n",
       "      <td>0.454119</td>\n",
       "      <td>0.997992</td>\n",
       "      <td>0.901822</td>\n",
       "      <td>0.339448</td>\n",
       "      <td>0.137110</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>frankie laine</td>\n",
       "      <td>i believe</td>\n",
       "      <td>1950</td>\n",
       "      <td>0</td>\n",
       "      <td>believe drop rain fall grow believe darkest ni...</td>\n",
       "      <td>51</td>\n",
       "      <td>0.035537</td>\n",
       "      <td>0.096777</td>\n",
       "      <td>0.443435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.331745</td>\n",
       "      <td>0.647540</td>\n",
       "      <td>0.954819</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.325021</td>\n",
       "      <td>0.263240</td>\n",
       "      <td>world/life</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>johnnie ray</td>\n",
       "      <td>cry</td>\n",
       "      <td>1950</td>\n",
       "      <td>0</td>\n",
       "      <td>sweetheart send letter goodbye secret feel bet...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.225422</td>\n",
       "      <td>0.456298</td>\n",
       "      <td>0.585288</td>\n",
       "      <td>0.840361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351814</td>\n",
       "      <td>0.139112</td>\n",
       "      <td>music</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    artist_name            track_name  release_date  genre  \\\n",
       "0           0         mukesh  mohabbat bhi jhoothi          1950      0   \n",
       "1           4  frankie laine             i believe          1950      0   \n",
       "2           6    johnnie ray                   cry          1950      0   \n",
       "\n",
       "                                              lyrics  len    dating  violence  \\\n",
       "0  hold time feel break feel untrue convince spea...   95  0.000598  0.063746   \n",
       "1  believe drop rain fall grow believe darkest ni...   51  0.035537  0.096777   \n",
       "2  sweetheart send letter goodbye secret feel bet...   24  0.002770  0.002770   \n",
       "\n",
       "   world/life  ...   sadness  feelings  danceability  loudness  acousticness  \\\n",
       "0    0.000598  ...  0.380299  0.117175      0.357739  0.454119      0.997992   \n",
       "1    0.443435  ...  0.001284  0.001284      0.331745  0.647540      0.954819   \n",
       "2    0.002770  ...  0.002770  0.225422      0.456298  0.585288      0.840361   \n",
       "\n",
       "   instrumentalness   valence    energy       topic  age  \n",
       "0          0.901822  0.339448  0.137110     sadness  1.0  \n",
       "1          0.000002  0.325021  0.263240  world/life  1.0  \n",
       "2          0.000000  0.351814  0.139112       music  1.0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df[\"genre\"].unique())\n",
    "\n",
    "genres = {'pop': 0, 'country': 1, 'blues': 2, 'jazz': 3, 'reggae': 4, 'rock': 5, 'hip hop': 6}\n",
    "df[\"genre\"] = df[\"genre\"].apply(genres.get)\n",
    "\n",
    "# check to make sure all the genres were successfully converted to numbers\n",
    "print(df[\"genre\"].unique())\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "0    0.248202\n",
       "1    0.191915\n",
       "2    0.162273\n",
       "3    0.135521\n",
       "4    0.088045\n",
       "5    0.142182\n",
       "6    0.031862\n",
       "dtype: float64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"genre\").size() / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like if we guess genre 0 (pop) every time, we will get a base accuracy of 24.8%. Let's see if we an do better than this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataFromDF(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        target = self.df['genre'].iloc[index]\n",
    "        lyrics = self.df['lyrics'].iloc[index]\n",
    "        features = self.df[engineered_features].iloc[index]\n",
    "        return target, lyrics, features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_val = train_test_split(df, shuffle = True, test_size = 0.2)\n",
    "train_data = TextDataFromDF(df_train)\n",
    "val_data   = TextDataFromDF(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " 'walk talk breathe try smile death finger pulse time time rest simple proposal walk line try borrow time moral story limit crew gonna choose tomorrow scene easy turn money green promise future wrong line walk keep take long rainbow morning follow gonna live tomorrow like live today borrow look stay',\n",
       " dating                      0.001224\n",
       " violence                    0.115240\n",
       " world/life                  0.354443\n",
       " night/time                  0.170155\n",
       " shake the audience          0.001224\n",
       " family/gospel               0.001224\n",
       " romantic                    0.001224\n",
       " communication               0.001224\n",
       " obscene                     0.001224\n",
       " music                       0.001224\n",
       " movement/places             0.255235\n",
       " light/visual perceptions    0.001224\n",
       " family/spiritual            0.001224\n",
       " like/girls                  0.041008\n",
       " sadness                     0.001224\n",
       " feelings                    0.001224\n",
       " danceability                0.352323\n",
       " loudness                    0.597134\n",
       " acousticness                0.000141\n",
       " instrumentalness            0.327935\n",
       " valence                     0.704246\n",
       " energy                      0.720712\n",
       " Name: 13728, dtype: float64)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[193]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['walk',\n",
       " 'talk',\n",
       " 'breathe',\n",
       " 'try',\n",
       " 'smile',\n",
       " 'death',\n",
       " 'finger',\n",
       " 'pulse',\n",
       " 'time',\n",
       " 'time',\n",
       " 'rest',\n",
       " 'simple',\n",
       " 'proposal',\n",
       " 'walk',\n",
       " 'line',\n",
       " 'try',\n",
       " 'borrow',\n",
       " 'time',\n",
       " 'moral',\n",
       " 'story',\n",
       " 'limit',\n",
       " 'crew',\n",
       " 'gonna',\n",
       " 'choose',\n",
       " 'tomorrow',\n",
       " 'scene',\n",
       " 'easy',\n",
       " 'turn',\n",
       " 'money',\n",
       " 'green',\n",
       " 'promise',\n",
       " 'future',\n",
       " 'wrong',\n",
       " 'line',\n",
       " 'walk',\n",
       " 'keep',\n",
       " 'take',\n",
       " 'long',\n",
       " 'rainbow',\n",
       " 'morning',\n",
       " 'follow',\n",
       " 'gonna',\n",
       " 'live',\n",
       " 'tomorrow',\n",
       " 'like',\n",
       " 'live',\n",
       " 'today',\n",
       " 'borrow',\n",
       " 'look',\n",
       " 'stay']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "tokenized = tokenizer(train_data[193][1])\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter):\n",
    "    for target, text, _ in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_data), specials=[\"<unk>\"], min_freq = 50)\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "max_len = 30\n",
    "num_tokens = len(vocab.get_itos())\n",
    "def text_pipeline(x):\n",
    "    tokens = vocab(tokenizer(x))\n",
    "    y = torch.zeros(max_len, dtype=torch.int64) + num_tokens\n",
    "    if len(tokens) > max_len:\n",
    "        tokens = tokens[0:max_len]\n",
    "    y[0:len(tokens)] = torch.tensor(tokens,dtype=torch.int64)\n",
    "    return y\n",
    "\n",
    "label_pipeline = lambda x: int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0,    0,   44, 2897, 2897, 2897, 2897, 2897, 2897, 2897, 2897, 2897,\n",
       "        2897, 2897, 2897, 2897, 2897, 2897, 2897, 2897, 2897, 2897, 2897, 2897,\n",
       "        2897, 2897, 2897, 2897, 2897, 2897])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline(\"we cant believe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def collate_batch(batch):\n",
    "    target_label_list = []\n",
    "    lyric_text_list = []\n",
    "    features_list = []  \n",
    "\n",
    "    for (_targets, _lyrics, _features) in batch:\n",
    "        # process targets\n",
    "        target_label_list.append(label_pipeline(_targets))\n",
    "\n",
    "        # process lyrics\n",
    "        processed_lyrics = text_pipeline(_lyrics)\n",
    "        lyric_text_list.append(processed_lyrics)\n",
    "\n",
    "        # process features\n",
    "        features_list.append(_features.to_numpy())\n",
    "\n",
    "    target_label_list = torch.tensor(target_label_list, dtype=(torch.int64))\n",
    "    lyric_text_list = torch.stack(lyric_text_list)\n",
    "    features_list = torch.tensor((features_list), dtype=torch.float64)\n",
    "\n",
    "    return target_label_list, lyric_text_list, features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=True, collate_fn=collate_batch)\n",
    "val_loader = DataLoader(val_data, batch_size=8, shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 2, 0, 1, 6, 4, 2]),\n",
       " tensor([[  35,    1,  108,   92,    1,   62,    0,  295,  604,    2,  481,   35,\n",
       "            77,    9,   14,  228,  246,  276,   35,   35,   58,   58,   58,   58,\n",
       "           127,   96,   35,   81,   32,   25],\n",
       "         [1264, 2779,   17,    0,    0,    0,  281,  830,  218,    0,   74,  167,\n",
       "           862, 1878, 1762, 1117, 1454,  256,    0,   55,  154,  154,    0, 1739,\n",
       "             0,    0,    0, 1473,  392,  496],\n",
       "         [ 815,  439,  717,   29, 1252, 2876,  147,    0,  140,   84, 1222,  311,\n",
       "          1669, 1295,  815,  439,  717,   29, 1252, 2876,  147,    0,  140,   84,\n",
       "          1222,  311, 1669, 1295, 2897, 2897],\n",
       "         [   0,  382,    0,    0,    0, 1963,  139,    0, 1942,    0, 1097, 2897,\n",
       "          2897, 2897, 2897, 2897, 2897, 2897, 2897, 2897, 2897, 2897, 2897, 2897,\n",
       "          2897, 2897, 2897, 2897, 2897, 2897],\n",
       "         [   0,   33,    0,    0,   82, 2469,    0,   81,  160,  170,  257,    0,\n",
       "           259,   33,   77, 2091,  527, 1901, 1174,  148,  684,   19,  261,    0,\n",
       "             0,    0,   95,  100,   45,  783],\n",
       "         [  38,  331,  298,    0,  780,    0,   35,   35,   81,  174,    0,    0,\n",
       "           516,    0,  142,    1,    0,   79,  951, 2374,   95,  806,   15,    0,\n",
       "           212,   17,   12,    0,  557,    0],\n",
       "         [ 716,    0,   68,  511,   28, 2314,  924,   29, 1915, 1551,  120,  583,\n",
       "            21, 1227,   68,  193,  885, 2234, 1232,   83, 2897, 2897, 2897, 2897,\n",
       "          2897, 2897, 2897, 2897, 2897, 2897],\n",
       "         [  12,  183,   41,  197,  150,   55,  459,   11,   94,  197,  150,   55,\n",
       "          2000,  262, 1011,    4, 1449,  140,  541,    5,  484,    4,  156,  183,\n",
       "           196,  197,  150,   55, 2000,  262]]),\n",
       " tensor([[8.4890e-04, 8.4890e-04, 8.4890e-04, 4.0088e-02, 8.4890e-04, 8.4890e-04,\n",
       "          3.6078e-02, 6.1065e-02, 2.2078e-02, 1.9050e-01, 8.4890e-04, 8.4890e-04,\n",
       "          8.4890e-04, 2.9738e-02, 4.1083e-01, 2.2231e-02, 4.1514e-01, 6.9546e-01,\n",
       "          6.9779e-01, 1.6194e-05, 1.1068e-01, 5.3752e-01],\n",
       "         [1.8797e-03, 2.0632e-01, 3.6854e-01, 1.8797e-03, 1.8797e-03, 1.8797e-03,\n",
       "          1.8797e-03, 1.8797e-03, 1.8797e-03, 2.3701e-01, 1.8797e-03, 8.1619e-02,\n",
       "          3.8763e-02, 1.8797e-03, 1.8797e-03, 4.3311e-02, 3.8915e-01, 7.0638e-01,\n",
       "          1.5261e-01, 4.4939e-01, 5.0330e-01, 6.6065e-01],\n",
       "         [4.0486e-03, 9.2713e-01, 4.0486e-03, 4.0486e-03, 4.0486e-03, 4.0486e-03,\n",
       "          4.0486e-03, 4.0486e-03, 4.0486e-03, 4.0486e-03, 4.0486e-03, 4.0486e-03,\n",
       "          4.0486e-03, 4.0486e-03, 4.0486e-03, 4.0486e-03, 3.6424e-01, 7.0989e-01,\n",
       "          7.6807e-05, 4.6964e-03, 4.5383e-01, 7.5975e-01],\n",
       "         [1.7544e-02, 3.5088e-01, 1.7544e-02, 1.7544e-02, 1.7544e-02, 1.7544e-02,\n",
       "          1.7544e-02, 1.7544e-02, 1.7544e-02, 1.7544e-02, 1.7544e-02, 1.7544e-02,\n",
       "          1.7544e-02, 3.5088e-01, 1.7544e-02, 1.7544e-02, 5.2345e-01, 7.4348e-01,\n",
       "          3.8252e-02, 0.0000e+00, 3.3739e-01, 4.6645e-01],\n",
       "         [1.1198e-03, 3.2208e-01, 1.1323e-01, 1.1198e-03, 1.1198e-03, 1.1198e-03,\n",
       "          2.7500e-02, 3.3270e-01, 9.0046e-02, 1.1198e-03, 1.1198e-03, 1.1198e-03,\n",
       "          5.5796e-02, 1.1198e-03, 1.1198e-03, 1.1198e-03, 4.1189e-01, 4.5812e-01,\n",
       "          9.1064e-01, 1.3360e-01, 3.8170e-01, 3.3531e-01],\n",
       "         [5.3706e-04, 4.7196e-02, 1.3929e-01, 5.3706e-04, 5.3706e-04, 5.3706e-04,\n",
       "          5.3706e-04, 6.2527e-02, 5.7175e-01, 5.6773e-02, 5.3706e-04, 5.3706e-04,\n",
       "          5.3706e-04, 5.3706e-04, 5.3706e-04, 1.7871e-02, 8.1263e-01, 6.4026e-01,\n",
       "          1.7469e-02, 2.0243e-06, 9.1138e-01, 6.2962e-01],\n",
       "         [4.7847e-03, 4.7847e-03, 4.7847e-03, 4.7847e-03, 4.7847e-03, 4.7847e-03,\n",
       "          4.7847e-03, 4.7847e-03, 4.7847e-03, 4.2536e-01, 4.7847e-03, 2.5726e-01,\n",
       "          2.4082e-01, 4.7847e-03, 4.7847e-03, 4.7847e-03, 7.3032e-01, 6.6374e-01,\n",
       "          5.1505e-02, 5.3441e-01, 6.1871e-01, 6.0760e-01],\n",
       "         [7.4699e-02, 4.7351e-01, 1.3495e-03, 1.3495e-03, 1.3495e-03, 1.3495e-03,\n",
       "          1.3495e-03, 1.3495e-03, 1.3495e-03, 1.2202e-01, 1.3495e-03, 1.3495e-03,\n",
       "          1.3495e-03, 1.3495e-03, 2.8153e-01, 1.3495e-03, 4.7796e-01, 7.9545e-01,\n",
       "          7.6305e-01, 0.0000e+00, 8.3203e-01, 4.6745e-01]], dtype=torch.float64))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class LyricClassificationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, max_len, num_class, dropout_p):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size+1, embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(max_len*embedding_dim, num_class)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.dropout(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 3\n",
    "num_class = 7\n",
    "dropout_p = 0.2\n",
    "model = LyricClassificationModel(vocab_size, embedding_dim, max_len, num_class, dropout_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(dataloader, d_type):\n",
    "    epoch_start_time = time.time()\n",
    "    # keep track of some counts for measuring accuracy\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 300\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, features) in enumerate(dataloader):\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if d_type == 'lyrics':\n",
    "            input_data = text\n",
    "        elif d_type == 'features':\n",
    "            input_data = features[idx]\n",
    "        else:  # 'both'\n",
    "            input_data = (text, features[idx])\n",
    "\n",
    "        # form prediction on batch\n",
    "        predicted_label = model(input_data)\n",
    "\n",
    "        # evaluate loss on prediction\n",
    "        loss = loss_fn(predicted_label, label)\n",
    "        # compute gradient\n",
    "        loss.backward()\n",
    "        # take an optimization step\n",
    "        optimizer.step()\n",
    "\n",
    "        # for printing accuracy\n",
    "        total_acc   += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        \n",
    "    print(f'| epoch {epoch:3d} | train accuracy {total_acc/total_count:8.3f} | time: {time.time() - epoch_start_time:5.2f}s')\n",
    "    \n",
    "def evaluate(dataloader, d_type):\n",
    "\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, features) in enumerate(dataloader):\n",
    "\n",
    "            if d_type == 'lyrics':\n",
    "                input_data = text\n",
    "            elif d_type == 'features':\n",
    "                input_data = features[idx]\n",
    "            else:  # 'both'\n",
    "                input_data = (text, features[idx])\n",
    "\n",
    "            predicted_label = model(input_data)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | train accuracy    0.204 | time: 44.38s\n",
      "| epoch   2 | train accuracy    0.231 | time: 45.90s\n",
      "| epoch   3 | train accuracy    0.261 | time: 48.69s\n",
      "| epoch   4 | train accuracy    0.276 | time: 44.80s\n",
      "| epoch   5 | train accuracy    0.281 | time: 47.53s\n",
      "| epoch   6 | train accuracy    0.292 | time: 44.49s\n",
      "| epoch   7 | train accuracy    0.290 | time: 42.61s\n",
      "| epoch   8 | train accuracy    0.300 | time: 42.15s\n",
      "| epoch   9 | train accuracy    0.296 | time: 47.53s\n",
      "| epoch  10 | train accuracy    0.301 | time: 50.76s\n",
      "| epoch  11 | train accuracy    0.305 | time: 51.45s\n",
      "| epoch  12 | train accuracy    0.300 | time: 49.81s\n",
      "| epoch  13 | train accuracy    0.302 | time: 49.77s\n",
      "| epoch  14 | train accuracy    0.300 | time: 49.35s\n",
      "| epoch  15 | train accuracy    0.302 | time: 48.89s\n",
      "| epoch  16 | train accuracy    0.300 | time: 45.99s\n",
      "| epoch  17 | train accuracy    0.299 | time: 44.35s\n",
      "| epoch  18 | train accuracy    0.303 | time: 44.38s\n",
      "| epoch  19 | train accuracy    0.303 | time: 44.09s\n",
      "| epoch  20 | train accuracy    0.298 | time: 45.52s\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(train_loader, 'lyrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25127753303964756"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(val_loader, 'lyrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class FeaturesClassificationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, max_len, num_class, dropout_p):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size+1, embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(max_len*embedding_dim, num_class)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.dropout(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.DoubleTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[161], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeatures\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[156], line 25\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataloader, d_type)\u001b[0m\n\u001b[0;32m     22\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m (text, features[idx])\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# form prediction on batch\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m predicted_label \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# evaluate loss on prediction\u001b[39;00m\n\u001b[0;32m     28\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(predicted_label, label)\n",
      "File \u001b[1;32mc:\\Users\\Zoe Greenwald\\anaconda3\\envs\\ml-0451-2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Zoe Greenwald\\anaconda3\\envs\\ml-0451-2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[154], line 12\u001b[0m, in \u001b[0;36mLyricClassificationModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 12\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n",
      "File \u001b[1;32mc:\\Users\\Zoe Greenwald\\anaconda3\\envs\\ml-0451-2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Zoe Greenwald\\anaconda3\\envs\\ml-0451-2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Zoe Greenwald\\anaconda3\\envs\\ml-0451-2\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Zoe Greenwald\\anaconda3\\envs\\ml-0451-2\\lib\\site-packages\\torch\\nn\\functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.DoubleTensor instead (while checking arguments for embedding)"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(train_loader, 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(val_loader, 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(train_loader, 'both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(val_loader, 'both')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-0451-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
