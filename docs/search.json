[
  {
    "objectID": "posts/new-test-post/index.html",
    "href": "posts/new-test-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "from source import Perceptron\np = Perceptron()\n\nI did it!!\nnot implemented\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-test-post/index.html#math",
    "href": "posts/new-test-post/index.html#math",
    "title": "Second Post",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/BP1.html",
    "href": "posts/BP1.html",
    "title": "Blog Post: Classifying Palmer Penguins",
    "section": "",
    "text": "Blog Post: Classifying Palmer Penguins\nIn this blog post, I aim to gain familiarity with pandas tools used for machine learning. I will be exploring a data set about penguins, and attempting to classify them by species based on individual quantitative and qualitative attributes. First, I will take a look at the data and clean it so that it is ready for use. Then I will get familiar with the data through graphical representations, in an effort to make the best decision about which features to use in modelling. Using a reproducible process, I will determine which 3 attributes (1 qualitative and 2 quantitative) should be used for the model. Cross-validation on the training data will be tested with several different models to determine the best model before moving on to the test data. Once the best model is determined, it will be run on the test data, with a goal of 100% accuracy of classification. To analyze the work, I will plot the species regions for both test and training data, and look at a confusion matrix before summing up my findings.\nBefore beginning analysis, the training data must be accessed.\n\nimport pandas as pd\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\n\nBelow is a sample of what it looks like:\n\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN\n\n\n\n\n\n\n\nClearly, this is a LOT of data. Furthermore, not all of it is super useful. For example, the studyName and Sample Number columns aren’t meaningful to this analysis. Some other columns, like Sex and Island need to be reformatted to allow for analysis. Now, I will clean the data.\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\ndef prepare_data(df):\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\"], axis = 1)\n  df = df[df[\"Sex\"] != \".\"]\n  df = df.dropna()\n  y = le.fit_transform(df[\"Species\"])\n  df = df.drop([\"Species\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(train)\nX_train.head()\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nStage_Adult, 1 Egg Stage\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n40.9\n16.6\n187.0\n3200.0\n9.08458\n-24.54903\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n1\n49.0\n19.5\n210.0\n3950.0\n9.53262\n-24.66867\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n2\n50.0\n15.2\n218.0\n5700.0\n8.25540\n-25.40075\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n3\n45.8\n14.6\n210.0\n4200.0\n7.79958\n-25.62618\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n4\n51.0\n18.8\n203.0\n4100.0\n9.23196\n-24.17282\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n\n\n\n\n\n\n\nExplore\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx = X_train['Flipper Length (mm)']\ny = X_train['Body Mass (g)']\n\nax = sns.scatterplot(data = X_train, x = 'Flipper Length (mm)', y = 'Body Mass (g)', hue = y_train)\n\nh,l = ax.get_legend_handles_labels()\n\nl = [\"Gentoo Penguin\", \"Chinstrap Penguin\", \"Adelie Penguin\"]\n\nax.legend(h, l)\nplt.show()\n\n\n\n\n\n\n\n\nTo be honest, I started out with some quantitative attributes that seemed interesting. Tossing them onto a graph organized by species seems to be a good way to get a feel of whether they could successfully be used as classifiers. While the combination of body mass and flipper length looks like it may be able to identify (2) penguins, it would be extremely difficult to differentiate penguins of species (0) and (1). Thus, I determined I should continue searching for more ideal attributes prior to modeling.\n\nx = X_train['Delta 15 N (o/oo)']\ny = X_train['Delta 13 C (o/oo)']\n\nax = sns.scatterplot(data=X_train, x = 'Delta 15 N (o/oo)', y = 'Delta 13 C (o/oo)', hue = y_train)\n\nh,l = ax.get_legend_handles_labels()\n\nl = [\"Gentoo Penguin\", \"Chinstrap Penguin\", \"Adelie Penguin\"]\n\nax.legend(h, l)\nplt.show()\n\n\n\n\n\n\n\n\nI threw a few new quantitative attributes on a graph to get an idea of how they compared. Once again, looking at the graph, I don’t have super high hopes that these would be successful as classifiers. It does appear that (1) penguins have a higher Delta 13 C (o/oo) than other species. (0) penguins overlapped with (1) penguins heavily for Delta 15 N (o/oo). (0) penguins also overlap heavily for Delta 13 C (o/oo) with (2) penguins, leading to a prediction that classification would be difficult.\n\nX_train.groupby(y_train)[['Island_Biscoe', 'Island_Dream', 'Island_Torgersen']].mean()\n\n\n\n\n\n\n\n\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\n\n\n\n\n0\n0.305556\n0.37963\n0.314815\n\n\n1\n0.000000\n1.00000\n0.000000\n\n\n2\n1.000000\n0.00000\n0.000000\n\n\n\n\n\n\n\nHere, I felt like I hit the jackpot. It seems that (1) penguins were only found on Island_Dream, and (2) pengiuns were only found on Island_Biscoe. Although (0) penguins are spread equally among all three islands, this simplifies the problem significantly. However, it is still important to run some tests and be aware of any possible overfitting.\nWith a few interesting graphics, and a summary table, it’s time to start modeling.\n\n\nModeling\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import mutual_info_classif\n\nx_new = SelectKBest(mutual_info_classif, k = 3)\nx_new.fit_transform(X_train, y_train)\nx_new.get_feature_names_out()\n\narray(['Culmen Depth (mm)', 'Flipper Length (mm)', 'Delta 13 C (o/oo)'],\n      dtype=object)\n\n\n\nfrom sklearn.svm import LinearSVC\nfrom sklearn.feature_selection import SelectFromModel\n\nlsvc = LinearSVC(C=0.001, penalty=\"l1\", dual=False).fit(X_train, y_train)\nmodel = SelectFromModel(lsvc, prefit=True).fit(X_train, y_train)\nx_new = model.transform(X_train)\nmodel.get_feature_names_out()\n\nc:\\Users\\Zoe Greenwald\\anaconda3\\envs\\ml-0451\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\n\n\narray(['Culmen Length (mm)', 'Flipper Length (mm)', 'Body Mass (g)'],\n      dtype=object)\n\n\nAfter trying two methods of features selection and getting only quantitative features, I’m going to give the brute force method a shot.\n\nfrom itertools import combinations\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\n\nqual_cols = [\"Island\", \"Clutch Completion\", \"Stage_adult\", \"Sex\"]\nquant_cols = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\", \"Flipper Length (mm)\", \"Body Mass (g)\", \"Delta 15 N (o/oo)\", \"Delta 13 C (o/oo)\"]\n\nbest_score = 0.0\nbest_cols = []\n\nfor qual in qual_cols: \n  qual_cols = [col for col in X_train.columns if qual in col ]\n  for pair in combinations(quant_cols, 2):\n    cols = qual_cols + list(pair) \n\n    LR = LogisticRegression(solver='lbfgs', max_iter = 10000)\n    LR.fit(X_train[cols], y_train)\n    score = LR.score(X_train[cols], y_train)\n\n    if score &gt; best_score:\n      best_score = score\n      best_cols = cols\n\n# puts the qualitative columns at the end \nbest_cols = best_cols[::-1]\n\nprint(best_cols)\nprint(best_score)\n\n['Culmen Depth (mm)', 'Culmen Length (mm)', 'Island_Torgersen', 'Island_Dream', 'Island_Biscoe']\n0.99609375\n\n\nSuccess! I may have forced it by looking only at groups of 3 that included 1 qualitative column, but I’ve managed to reproducibly find the columns I want to use for my modelling. Culmen depth, culmen length, and island seem to have a high success rate for classifying the three penguin species.\n\ncv_scores_LR = cross_val_score(LR, X_train[best_cols], y_train, cv=5).mean()\nprint(cv_scores_LR)\n\n0.9883107088989442\n\n\n\nfrom sklearn.tree import DecisionTreeClassifier\nimport numpy as np\n\ndepths = [*range(3, 20)]\ncv_scores_dtc = []\n\nfor val in depths:\n    dtc = DecisionTreeClassifier(criterion=\"gini\", max_depth=val).fit(X_train[best_cols], y_train)\n    cv_scores_dtc.append(cross_val_score(dtc, X_train[best_cols], y_train, cv=5).mean())\n\nbest_score = np.max(cv_scores_dtc)\nbest_depth = depths[np.argmax(cv_scores_dtc)]\nprint(best_score)\nprint(best_depth)\n\n0.9765460030165913\n7\n\n\n\nfrom sklearn.ensemble import RandomForestClassifier\n\ntrees = [*range(10, 100)]\ncv_scores_rf = []\n\nfor val in trees:\n    rf = RandomForestClassifier(n_estimators = val).fit(X_train[best_cols], y_train)\n    cv_scores_rf.append(cross_val_score(rf, X_train[best_cols], y_train, cv=5).mean())\n\nbest_score = np.max(cv_scores_rf)\nbest_depth = trees[np.argmax(cv_scores_rf)]\nprint(best_score)\nprint(best_depth)\n\n0.9843891402714933\n16\n\n\n\n\nTesting\nLooking at the scores of the best fits of all the tested models, it looks like LR pulls ahead by just a fraction of a percent, so I’ll go ahead and try that on the test data.\n\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\nX_test, y_test = prepare_data(test)\n\nLR.fit(X_train[best_cols], y_train)\nLR.score(X_test[best_cols], y_test)\n\n1.0\n\n\nWe did it! With enough modeling and praying, we got 100% accuracy on the test data! Woohoo!!!\n\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (7, 3))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i])\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"upper right\", bbox_to_anchor = (2.5, 0.75))\n      \n      plt.tight_layout()\n\n\nplot_regions(LR, X_train[best_cols], y_train)\n\n\n\n\n\n\n\n\n\nplot_regions(LR, X_test[best_cols], y_test)\n\n\n\n\n\n\n\n\nTo finish up, lets take a look at the confusion matrix to see what kind of mistakes our model made (even though our model didn’t make any mistakes on the test data).\n\nfrom sklearn.metrics import confusion_matrix\n\ny_test_pred = LR.predict(X_test[best_cols])\nC = confusion_matrix(y_test, y_test_pred)\nC\n\narray([[31,  0,  0],\n       [ 0, 11,  0],\n       [ 0,  0, 26]], dtype=int64)\n\n\nGiven that our model had 100% accuracy on the test set, this was the confusion matrix I was expecting. The only non-zero numbers are along the diagonal, signifying that every penguin was correctly classified as its own species.\nTo close out this first blog post, I will first discuss my results, and then my learnings. I found that I was able to use machine learning on training data to prepare an group of features and model to successfully classify penguins into their respective species group. The optimal features ended up being culmen length, culmen depth, and what island the penguin was found on, and I determined the ideal model to be linear regression after using cross-validation on several different models before applying the algorithm to the test data. I was excited to meet Phil’s request for 100% accuracy on the test data. Some further analysis was done to compare the decision regions and their boundaries between the train and test data sets. I learned a lot about pandas feature selections and models in this assignment, along with the basic flow of using machine learning in a data science project."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Updated",
    "section": "",
    "text": "Some new text here"
  },
  {
    "objectID": "posts/example-blog-post/index.html",
    "href": "posts/example-blog-post/index.html",
    "title": "Hello Blog",
    "section": "",
    "text": "from source import Perceptron\np = Perceptron()\n\nI did it!!\nnot implemented\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/example-blog-post/index.html#math",
    "href": "posts/example-blog-post/index.html#math",
    "title": "Hello Blog",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  }
]