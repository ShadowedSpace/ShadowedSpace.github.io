{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/PhilChodrow/PIC16B/master/datasets/tcc_ceds_music.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>release_date</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>len</th>\n",
       "      <th>dating</th>\n",
       "      <th>violence</th>\n",
       "      <th>world/life</th>\n",
       "      <th>...</th>\n",
       "      <th>sadness</th>\n",
       "      <th>feelings</th>\n",
       "      <th>danceability</th>\n",
       "      <th>loudness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>energy</th>\n",
       "      <th>topic</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mukesh</td>\n",
       "      <td>mohabbat bhi jhoothi</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>hold time feel break feel untrue convince spea...</td>\n",
       "      <td>95</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.063746</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380299</td>\n",
       "      <td>0.117175</td>\n",
       "      <td>0.357739</td>\n",
       "      <td>0.454119</td>\n",
       "      <td>0.997992</td>\n",
       "      <td>0.901822</td>\n",
       "      <td>0.339448</td>\n",
       "      <td>0.137110</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>frankie laine</td>\n",
       "      <td>i believe</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>believe drop rain fall grow believe darkest ni...</td>\n",
       "      <td>51</td>\n",
       "      <td>0.035537</td>\n",
       "      <td>0.096777</td>\n",
       "      <td>0.443435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.331745</td>\n",
       "      <td>0.647540</td>\n",
       "      <td>0.954819</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.325021</td>\n",
       "      <td>0.263240</td>\n",
       "      <td>world/life</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>johnnie ray</td>\n",
       "      <td>cry</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>sweetheart send letter goodbye secret feel bet...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.225422</td>\n",
       "      <td>0.456298</td>\n",
       "      <td>0.585288</td>\n",
       "      <td>0.840361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351814</td>\n",
       "      <td>0.139112</td>\n",
       "      <td>music</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>pérez prado</td>\n",
       "      <td>patricia</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>kiss lips want stroll charm mambo chacha merin...</td>\n",
       "      <td>54</td>\n",
       "      <td>0.048249</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225889</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.686992</td>\n",
       "      <td>0.744404</td>\n",
       "      <td>0.083935</td>\n",
       "      <td>0.199393</td>\n",
       "      <td>0.775350</td>\n",
       "      <td>0.743736</td>\n",
       "      <td>romantic</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>giorgos papadopoulos</td>\n",
       "      <td>apopse eida oneiro</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>till darling till matter know till dream live ...</td>\n",
       "      <td>48</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.417772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.291671</td>\n",
       "      <td>0.646489</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.597073</td>\n",
       "      <td>0.394375</td>\n",
       "      <td>romantic</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           artist_name            track_name  release_date genre  \\\n",
       "0           0                mukesh  mohabbat bhi jhoothi          1950   pop   \n",
       "1           4         frankie laine             i believe          1950   pop   \n",
       "2           6           johnnie ray                   cry          1950   pop   \n",
       "3          10           pérez prado              patricia          1950   pop   \n",
       "4          12  giorgos papadopoulos    apopse eida oneiro          1950   pop   \n",
       "\n",
       "                                              lyrics  len    dating  violence  \\\n",
       "0  hold time feel break feel untrue convince spea...   95  0.000598  0.063746   \n",
       "1  believe drop rain fall grow believe darkest ni...   51  0.035537  0.096777   \n",
       "2  sweetheart send letter goodbye secret feel bet...   24  0.002770  0.002770   \n",
       "3  kiss lips want stroll charm mambo chacha merin...   54  0.048249  0.001548   \n",
       "4  till darling till matter know till dream live ...   48  0.001350  0.001350   \n",
       "\n",
       "   world/life  ...   sadness  feelings  danceability  loudness  acousticness  \\\n",
       "0    0.000598  ...  0.380299  0.117175      0.357739  0.454119      0.997992   \n",
       "1    0.443435  ...  0.001284  0.001284      0.331745  0.647540      0.954819   \n",
       "2    0.002770  ...  0.002770  0.225422      0.456298  0.585288      0.840361   \n",
       "3    0.001548  ...  0.225889  0.001548      0.686992  0.744404      0.083935   \n",
       "4    0.417772  ...  0.068800  0.001350      0.291671  0.646489      0.975904   \n",
       "\n",
       "   instrumentalness   valence    energy       topic  age  \n",
       "0          0.901822  0.339448  0.137110     sadness  1.0  \n",
       "1          0.000002  0.325021  0.263240  world/life  1.0  \n",
       "2          0.000000  0.351814  0.139112       music  1.0  \n",
       "3          0.199393  0.775350  0.743736    romantic  1.0  \n",
       "4          0.000246  0.597073  0.394375    romantic  1.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_features = ['dating', 'violence', 'world/life', 'night/time','shake the audience','family/gospel', 'romantic', 'communication','obscene', 'music', 'movement/places', 'light/visual perceptions','family/spiritual', 'like/girls', 'sadness', 'feelings', 'danceability','loudness', 'acousticness', 'instrumentalness', 'valence', 'energy'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pop' 'country' 'blues' 'jazz' 'reggae' 'rock' 'hip hop']\n",
      "[0 1 2 3 4 5 6]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>release_date</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>len</th>\n",
       "      <th>dating</th>\n",
       "      <th>violence</th>\n",
       "      <th>world/life</th>\n",
       "      <th>...</th>\n",
       "      <th>sadness</th>\n",
       "      <th>feelings</th>\n",
       "      <th>danceability</th>\n",
       "      <th>loudness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>energy</th>\n",
       "      <th>topic</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mukesh</td>\n",
       "      <td>mohabbat bhi jhoothi</td>\n",
       "      <td>1950</td>\n",
       "      <td>0</td>\n",
       "      <td>hold time feel break feel untrue convince spea...</td>\n",
       "      <td>95</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.063746</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380299</td>\n",
       "      <td>0.117175</td>\n",
       "      <td>0.357739</td>\n",
       "      <td>0.454119</td>\n",
       "      <td>0.997992</td>\n",
       "      <td>0.901822</td>\n",
       "      <td>0.339448</td>\n",
       "      <td>0.137110</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>frankie laine</td>\n",
       "      <td>i believe</td>\n",
       "      <td>1950</td>\n",
       "      <td>0</td>\n",
       "      <td>believe drop rain fall grow believe darkest ni...</td>\n",
       "      <td>51</td>\n",
       "      <td>0.035537</td>\n",
       "      <td>0.096777</td>\n",
       "      <td>0.443435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.331745</td>\n",
       "      <td>0.647540</td>\n",
       "      <td>0.954819</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.325021</td>\n",
       "      <td>0.263240</td>\n",
       "      <td>world/life</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>johnnie ray</td>\n",
       "      <td>cry</td>\n",
       "      <td>1950</td>\n",
       "      <td>0</td>\n",
       "      <td>sweetheart send letter goodbye secret feel bet...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.225422</td>\n",
       "      <td>0.456298</td>\n",
       "      <td>0.585288</td>\n",
       "      <td>0.840361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351814</td>\n",
       "      <td>0.139112</td>\n",
       "      <td>music</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    artist_name            track_name  release_date  genre  \\\n",
       "0           0         mukesh  mohabbat bhi jhoothi          1950      0   \n",
       "1           4  frankie laine             i believe          1950      0   \n",
       "2           6    johnnie ray                   cry          1950      0   \n",
       "\n",
       "                                              lyrics  len    dating  violence  \\\n",
       "0  hold time feel break feel untrue convince spea...   95  0.000598  0.063746   \n",
       "1  believe drop rain fall grow believe darkest ni...   51  0.035537  0.096777   \n",
       "2  sweetheart send letter goodbye secret feel bet...   24  0.002770  0.002770   \n",
       "\n",
       "   world/life  ...   sadness  feelings  danceability  loudness  acousticness  \\\n",
       "0    0.000598  ...  0.380299  0.117175      0.357739  0.454119      0.997992   \n",
       "1    0.443435  ...  0.001284  0.001284      0.331745  0.647540      0.954819   \n",
       "2    0.002770  ...  0.002770  0.225422      0.456298  0.585288      0.840361   \n",
       "\n",
       "   instrumentalness   valence    energy       topic  age  \n",
       "0          0.901822  0.339448  0.137110     sadness  1.0  \n",
       "1          0.000002  0.325021  0.263240  world/life  1.0  \n",
       "2          0.000000  0.351814  0.139112       music  1.0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df[\"genre\"].unique())\n",
    "\n",
    "genres = {'pop': 0, 'country': 1, 'blues': 2, 'jazz': 3, 'reggae': 4, 'rock': 5, 'hip hop': 6}\n",
    "df[\"genre\"] = df[\"genre\"].apply(genres.get)\n",
    "\n",
    "# check to make sure all the genres were successfully converted to numbers\n",
    "print(df[\"genre\"].unique())\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "0    0.248202\n",
       "1    0.191915\n",
       "2    0.162273\n",
       "3    0.135521\n",
       "4    0.088045\n",
       "5    0.142182\n",
       "6    0.031862\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"genre\").size() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataFromDF(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        lyrics = self.df['lyrics'].iloc[index]  # replace 'lyrics' with your actual column name\n",
    "        features = self.df[engineered_features].iloc[index]  # replace with your actual feature column names\n",
    "        return lyrics, features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_val = train_test_split(df, shuffle = True, test_size = 0.2)\n",
    "train_data = TextDataFromDF(df_train)\n",
    "val_data   = TextDataFromDF(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('jarabi kèlèla furunyògòn kèlèla bolo bolo cèkisè bolo dusu kolo diminna jarabi kanu jarabi kanu hodounannnn dusu kolo diminna jarabi kanu jarabi kanu hodounannnn bolo bolo cèkisè bolo bolo bolo bolo bolo cèkisè bolo bolo bolo bolo bolo cèkisè bolo kunkolo bolo argue argue husband hand longer touch neck hand longer touch waist hand longer stroke hair longer look heart ache darling follow hand longer touch neck hand longer touch waist hand longer touch breast hand longer caress head heart ache hand longer caress breast hand longer touch waist hand longer caress hair hand longer touch neck hand longer touch',\n",
       " dating                      0.001170\n",
       " violence                    0.167977\n",
       " world/life                  0.001170\n",
       " night/time                  0.001170\n",
       " shake the audience          0.001170\n",
       " family/gospel               0.299718\n",
       " romantic                    0.513591\n",
       " communication               0.001170\n",
       " obscene                     0.001170\n",
       " music                       0.001170\n",
       " movement/places             0.001170\n",
       " light/visual perceptions    0.001170\n",
       " family/spiritual            0.001170\n",
       " like/girls                  0.001170\n",
       " sadness                     0.001170\n",
       " feelings                    0.001170\n",
       " danceability                0.715152\n",
       " loudness                    0.535600\n",
       " acousticness                0.582329\n",
       " instrumentalness            0.181174\n",
       " valence                     0.908285\n",
       " energy                      0.470454\n",
       " Name: 16352, dtype: float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[194]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jarabi',\n",
       " 'kèlèla',\n",
       " 'furunyògòn',\n",
       " 'kèlèla',\n",
       " 'bolo',\n",
       " 'bolo',\n",
       " 'cèkisè',\n",
       " 'bolo',\n",
       " 'dusu',\n",
       " 'kolo',\n",
       " 'diminna',\n",
       " 'jarabi',\n",
       " 'kanu',\n",
       " 'jarabi',\n",
       " 'kanu',\n",
       " 'hodounannnn',\n",
       " 'dusu',\n",
       " 'kolo',\n",
       " 'diminna',\n",
       " 'jarabi',\n",
       " 'kanu',\n",
       " 'jarabi',\n",
       " 'kanu',\n",
       " 'hodounannnn',\n",
       " 'bolo',\n",
       " 'bolo',\n",
       " 'cèkisè',\n",
       " 'bolo',\n",
       " 'bolo',\n",
       " 'bolo',\n",
       " 'bolo',\n",
       " 'bolo',\n",
       " 'cèkisè',\n",
       " 'bolo',\n",
       " 'bolo',\n",
       " 'bolo',\n",
       " 'bolo',\n",
       " 'bolo',\n",
       " 'cèkisè',\n",
       " 'bolo',\n",
       " 'kunkolo',\n",
       " 'bolo',\n",
       " 'argue',\n",
       " 'argue',\n",
       " 'husband',\n",
       " 'hand',\n",
       " 'longer',\n",
       " 'touch',\n",
       " 'neck',\n",
       " 'hand',\n",
       " 'longer',\n",
       " 'touch',\n",
       " 'waist',\n",
       " 'hand',\n",
       " 'longer',\n",
       " 'stroke',\n",
       " 'hair',\n",
       " 'longer',\n",
       " 'look',\n",
       " 'heart',\n",
       " 'ache',\n",
       " 'darling',\n",
       " 'follow',\n",
       " 'hand',\n",
       " 'longer',\n",
       " 'touch',\n",
       " 'neck',\n",
       " 'hand',\n",
       " 'longer',\n",
       " 'touch',\n",
       " 'waist',\n",
       " 'hand',\n",
       " 'longer',\n",
       " 'touch',\n",
       " 'breast',\n",
       " 'hand',\n",
       " 'longer',\n",
       " 'caress',\n",
       " 'head',\n",
       " 'heart',\n",
       " 'ache',\n",
       " 'hand',\n",
       " 'longer',\n",
       " 'caress',\n",
       " 'breast',\n",
       " 'hand',\n",
       " 'longer',\n",
       " 'touch',\n",
       " 'waist',\n",
       " 'hand',\n",
       " 'longer',\n",
       " 'caress',\n",
       " 'hair',\n",
       " 'hand',\n",
       " 'longer',\n",
       " 'touch',\n",
       " 'neck',\n",
       " 'hand',\n",
       " 'longer',\n",
       " 'touch']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "tokenized = tokenizer(train_data[194][0])\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter):\n",
    "    for text, _ in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_data), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "max_len = 30\n",
    "num_tokens = len(vocab.get_itos())\n",
    "def text_pipeline(x):\n",
    "    tokens = vocab(tokenizer(x))\n",
    "    y = torch.zeros(max_len, dtype=torch.int64) + num_tokens\n",
    "    if len(tokens) > max_len:\n",
    "        tokens = tokens[0:max_len]\n",
    "    y[0:len(tokens)] = torch.tensor(tokens,dtype=torch.int64)\n",
    "    return y\n",
    "\n",
    "label_pipeline = lambda x: int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0, 27364,    49, 45701, 45701, 45701, 45701, 45701, 45701, 45701,\n",
       "        45701, 45701, 45701, 45701, 45701, 45701, 45701, 45701, 45701, 45701,\n",
       "        45701, 45701, 45701, 45701, 45701, 45701, 45701, 45701, 45701, 45701])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline(\"we cant believe\")\n",
    "#print(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    lyric_label_list, lyric_text_list = [], []\n",
    "    features_label_list, features_text_list = [], []\n",
    "\n",
    "    for (_lyrics, _features) in batch:\n",
    "        # process lyrics\n",
    "        lyric_label_list.append(label_pipeline(_lyrics))\n",
    "        processed_lyrics = text_pipeline(_lyrics)\n",
    "        lyric_text_list.append(processed_lyrics)\n",
    "\n",
    "        # process features\n",
    "        features_label_list.append(label_pipeline(_features))\n",
    "        processed_features = text_pipeline(_features)\n",
    "        features_text_list.append(processed_features)\n",
    "\n",
    "    lyric_label_list = torch.tensor(lyric_label_list, dtype=torch.int64)\n",
    "    lyric_text_list = torch.stack(lyric_text_list)\n",
    "    features_label_list = torch.tensor(features_label_list, dtype=torch.int64)\n",
    "    features_text_list = torch.stack(features_text_list)\n",
    "    \n",
    "    return lyric_text_list, lyric_label_list, features_text_list, features_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=True, collate_fn=collate_batch)\n",
    "val_loader = DataLoader(val_data, batch_size=8, shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'know look look eye fair line hold gonna need little time fall break heart mend know gonna pull know fall scar guess scar long trust sure come know hurt hard inside arm feel ready fall break heart men",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Zoe Greenwald\\anaconda3\\envs\\ml-0451-2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Zoe Greenwald\\anaconda3\\envs\\ml-0451-2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Zoe Greenwald\\anaconda3\\envs\\ml-0451-2\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 7\u001b[0m, in \u001b[0;36mcollate_batch\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m      3\u001b[0m features_label_list, features_text_list \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_lyrics, _features) \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# process lyrics\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     lyric_label_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43mlabel_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_lyrics\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      8\u001b[0m     processed_lyrics \u001b[38;5;241m=\u001b[39m text_pipeline(_lyrics)\n\u001b[0;32m      9\u001b[0m     lyric_text_list\u001b[38;5;241m.\u001b[39mappend(processed_lyrics)\n",
      "Cell \u001b[1;32mIn[11], line 13\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     10\u001b[0m     y[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mlen\u001b[39m(tokens)] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(tokens,dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n\u001b[1;32m---> 13\u001b[0m label_pipeline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'know look look eye fair line hold gonna need little time fall break heart mend know gonna pull know fall scar guess scar long trust sure come know hurt hard inside arm feel ready fall break heart men"
     ]
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class LyricClassificationModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, max_len, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size+1, embedding_dim)\n",
    "        self.fc   = nn.Linear(max_len*embedding_dim, num_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 3\n",
    "model = LyricClassificationModel(vocab_size, embedding_dim, max_len, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.1)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(dataloader):\n",
    "    epoch_start_time = time.time()\n",
    "    # keep track of some counts for measuring accuracy\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 300\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (text, label) in enumerate(dataloader):\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        # form prediction on batch\n",
    "        predicted_label = model(text)\n",
    "        # evaluate loss on prediction\n",
    "        loss = loss_fn(predicted_label, label)\n",
    "        # compute gradient\n",
    "        loss.backward()\n",
    "        # take an optimization step\n",
    "        optimizer.step()\n",
    "\n",
    "        # for printing accuracy\n",
    "        total_acc   += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        \n",
    "    print(f'| epoch {epoch:3d} | train accuracy {total_acc/total_count:8.3f} | time: {time.time() - epoch_start_time:5.2f}s')\n",
    "    \n",
    "def evaluate(dataloader):\n",
    "\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (text, label) in enumerate(dataloader):\n",
    "            predicted_label = model(text)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | train accuracy    0.177 | time: 12.85s\n",
      "| epoch   2 | train accuracy    0.180 | time: 14.37s\n",
      "| epoch   3 | train accuracy    0.185 | time: 13.76s\n",
      "| epoch   4 | train accuracy    0.195 | time: 13.77s\n",
      "| epoch   5 | train accuracy    0.209 | time: 13.88s\n",
      "| epoch   6 | train accuracy    0.219 | time: 14.09s\n",
      "| epoch   7 | train accuracy    0.227 | time: 14.21s\n",
      "| epoch   8 | train accuracy    0.244 | time: 14.27s\n",
      "| epoch   9 | train accuracy    0.254 | time: 14.24s\n",
      "| epoch  10 | train accuracy    0.272 | time: 14.65s\n",
      "| epoch  11 | train accuracy    0.290 | time: 14.11s\n",
      "| epoch  12 | train accuracy    0.298 | time: 14.49s\n",
      "| epoch  13 | train accuracy    0.306 | time: 14.43s\n",
      "| epoch  14 | train accuracy    0.318 | time: 1162.26s\n",
      "| epoch  15 | train accuracy    0.335 | time: 28.82s\n",
      "| epoch  16 | train accuracy    0.341 | time: 31.16s\n",
      "| epoch  17 | train accuracy    0.352 | time: 30.41s\n",
      "| epoch  18 | train accuracy    0.366 | time: 30.41s\n",
      "| epoch  19 | train accuracy    0.373 | time: 30.89s\n",
      "| epoch  20 | train accuracy    0.383 | time: 30.94s\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20052863436123347"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-0451-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
